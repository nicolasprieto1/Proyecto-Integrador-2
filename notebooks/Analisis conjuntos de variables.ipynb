{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de conjuntos de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Realizamos el cambio de directoroi de trabajo al \"Directorio Base\" que se\n",
    "current_dir = os.getcwd()\n",
    "base_path = os.path.dirname(current_dir)\n",
    "\n",
    "os.chdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasal\\Anaconda3\\envs\\PI2\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import scripts.funciones as funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.base import clone\n",
    "from xgboost import XGBClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga y preparaci√≥n de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 456 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "version = 'verFinal'\n",
    "\n",
    "X_train_under = pd.read_csv('data/train.csv')\n",
    "Y_train_under = X_train_under['Accidente']\n",
    "X_train_under = X_train_under.drop(columns = ['TW','BARRIO','Accidente'])\n",
    "\n",
    "X_val = pd.read_csv('data/validation.csv')\n",
    "Y_val = X_val['Accidente']\n",
    "X_val = X_val.drop(columns = ['TW','BARRIO','Accidente'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Estandarizacion del conjunto de datos\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_under)\n",
    "\n",
    "X_train_under_z = pd.DataFrame(scaler.transform(X_train_under), columns = X_train_under.columns)\n",
    "X_val_z = pd.DataFrame(scaler.transform(X_val), columns = X_val.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de modelos eliminando conjuntos de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier1 = MLPClassifier(activation='identity', alpha=0.05,\n",
    "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
    "                               early_stopping=False, epsilon=1e-08,\n",
    "                               hidden_layer_sizes=(29, 53),\n",
    "                               learning_rate='constant',\n",
    "                               learning_rate_init=0.001, max_fun=15000,\n",
    "                               max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
    "                               nesterovs_momentum=True, power_t=0.5,\n",
    "                               random_state=42, shuffle=True, solver='adam',\n",
    "                               tol=0.0001, validation_fraction=0.1,\n",
    "                               verbose=False, warm_start=False)\n",
    "\n",
    "Classifier2 = ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0,\n",
    "                                      class_weight=None, criterion='entropy',\n",
    "                                      max_depth=20, max_features='log2',\n",
    "                                      max_leaf_nodes=None, max_samples=None,\n",
    "                                      min_impurity_decrease=0.0,\n",
    "                                      min_impurity_split=None,\n",
    "                                      min_samples_leaf=1, min_samples_split=2,\n",
    "                                      min_weight_fraction_leaf=0.0,\n",
    "                                      n_estimators=500, n_jobs=None,\n",
    "                                      oob_score=False, random_state=42,\n",
    "                                      verbose=0, warm_start=False)\n",
    "\n",
    "Classifier3 = LogisticRegression(C=0.6453715401646702, class_weight=None,\n",
    "                                    dual=False, fit_intercept=True,\n",
    "                                    intercept_scaling=1, l1_ratio=None,\n",
    "                                    max_iter=100, multi_class='auto',\n",
    "                                    n_jobs=None, penalty='l1', random_state=42,\n",
    "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
    "                                    warm_start=False)\n",
    "\n",
    "VotingClassifier = EnsembleVoteClassifier(clfs=[Classifier1, Classifier2, Classifier3], weights=[1,1,1], refit=True)\n",
    "\n",
    "\n",
    "clasificadores = [VotingClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'vars_relevantes_final.json'\n",
    "path = os.path.join(base_path, f'models/verFinal/{file_name}')\n",
    "with open(path, 'r') as f:\n",
    "    info_vars = json.load(f)\n",
    "\n",
    "vars_voto = info_vars['voto']['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtencion_metricas(clasificadores,variables,X,Y,X_val,Y_val):\n",
    "    \n",
    "    ROC = []\n",
    "    PR = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    fscore = []\n",
    "    bAccuracY = []\n",
    "\n",
    "    for clf in clasificadores:\n",
    "        clf_mod = clone(clf)\n",
    "        clf_mod.fit(X[variables],Y)\n",
    "\n",
    "        ### Metricas en validation\n",
    "\n",
    "        preds_val = clf_mod.predict_proba(X_val[variables])\n",
    "        labels_val = clf_mod.predict(X_val[variables])\n",
    "\n",
    "        ROC_mod = metrics.roc_auc_score(Y_val,preds_val[:,1])\n",
    "        PR_mod = funciones.precision_recall_auc_score(Y_val,preds_val[:,1])\n",
    "        precision_mod = metrics.precision_score(Y_val,labels_val)\n",
    "        recall_mod = metrics.recall_score(Y_val,labels_val)\n",
    "        f1_mod = metrics.f1_score(Y_val,labels_val)\n",
    "        bAccuracY_mod = metrics.balanced_accuracy_score(Y_val,labels_val)\n",
    "\n",
    "        ROC.append(ROC_mod)\n",
    "        PR.append(PR_mod)\n",
    "        precision.append(precision_mod) \n",
    "        recall.append(recall_mod)\n",
    "        fscore.append(f1_mod)\n",
    "        bAccuracY.append(bAccuracY_mod)\n",
    "\n",
    "\n",
    "    print(f'Mean ROC: {np.mean(ROC)}')\n",
    "    print(f'Mean PR: {np.mean(PR)}')\n",
    "    print(f'Mean Precision: {np.mean(precision)}')\n",
    "    print(f'Mean Recall: {np.mean(recall)}')\n",
    "    print(f'Mean F Score: {np.mean(fscore)}')\n",
    "    print(f'Mean Balanced Accuracy: {np.mean(bAccuracY)}')\n",
    "    \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vars elegidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC: 0.7844021022705707\n",
      "Mean PR: 0.060799060893915374\n",
      "Mean Precision: 0.06569724866617847\n",
      "Mean Recall: 0.45244956772334294\n",
      "Mean F Score: 0.11473463049237234\n",
      "Mean Balanced Accuracy: 0.666029051685836\n"
     ]
    }
   ],
   "source": [
    "obtencion_metricas(clasificadores,vars_voto,X_train_under_z,Y_train_under,X_val_z,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando variables relacionadas al barrio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC: 0.7739596459429462\n",
      "Mean PR: 0.057630758829553916\n",
      "Mean Precision: 0.06656184486373165\n",
      "Mean Recall: 0.3659942363112392\n",
      "Mean F Score: 0.11263858093126385\n",
      "Mean Balanced Accuracy: 0.6349807262599023\n"
     ]
    }
   ],
   "source": [
    "vars_sinBarrio = []\n",
    "for col in vars_voto:\n",
    "    if not 'poblado' in col:\n",
    "        vars_sinBarrio.append(col)\n",
    "\n",
    "obtencion_metricas(clasificadores,vars_sinBarrio,X_train_under_z,Y_train_under,X_val_z,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando variables relacionadas al barrio y senales de accidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC: 0.7323888571998968\n",
      "Mean PR: 0.0416509520816257\n",
      "Mean Precision: 0.04997139042532901\n",
      "Mean Recall: 0.18876080691642652\n",
      "Mean F Score: 0.07902277182928669\n",
      "Mean Balanced Accuracy: 0.5608080216456687\n"
     ]
    }
   ],
   "source": [
    "vars_sinBarrio_acc = []\n",
    "for col in vars_voto:\n",
    "    if (not 'poblado' in col) and (not 'cumAcc' in col):\n",
    "        vars_sinBarrio_acc.append(col)\n",
    "        \n",
    "obtencion_metricas(clasificadores,vars_sinBarrio_acc,X_train_under_z,Y_train_under,X_val_z,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando variables climaticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC: 0.7791964423519826\n",
      "Mean PR: 0.05837387017684498\n",
      "Mean Precision: 0.06272401433691756\n",
      "Mean Recall: 0.42867435158501443\n",
      "Mean F Score: 0.10943535037704616\n",
      "Mean Balanced Accuracy: 0.6544110471646545\n"
     ]
    }
   ],
   "source": [
    "clima = ['precipIntensity',\n",
    "         'precipProbability',\n",
    "         'uvIndex',\n",
    "         'visibility',\n",
    "          'icon_clear-day',\n",
    "         'icon_cloudy',\n",
    "         'icon_fog',\n",
    "          'cloudCover_mean',\n",
    "         'precipIntensity_mean',\n",
    "         'visibility_mean',\n",
    "         'windSpeed_mean',\n",
    "         'cloudCover_mean_forward',\n",
    "         'dewPoint_mean_forward',\n",
    "         'precipIntensity_mean_forward',\n",
    "         'temperature_mean_forward']\n",
    "\n",
    "vars_sinClima = []\n",
    "for col in vars_voto:\n",
    "    if not col in clima:\n",
    "        vars_sinClima.append(col)\n",
    "\n",
    "obtencion_metricas(clasificadores,vars_sinClima,X_train_under_z,Y_train_under,X_val_z,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando senal de accidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC: 0.7850353695380856\n",
      "Mean PR: 0.06072219233763472\n",
      "Mean Precision: 0.06737149926892363\n",
      "Mean Recall: 0.4315561959654179\n",
      "Mean F Score: 0.11654830236404319\n",
      "Mean Balanced Accuracy: 0.659889282485897\n"
     ]
    }
   ],
   "source": [
    "vars_sinAccidente = []\n",
    "for col in vars_voto:\n",
    "    if not 'cumAcc' in col:\n",
    "        vars_sinAccidente.append(col)\n",
    "\n",
    "obtencion_metricas(clasificadores,vars_sinAccidente,X_train_under_z,Y_train_under,X_val_z,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando las temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC: 0.7538172890539677\n",
      "Mean PR: 0.051218777882587024\n",
      "Mean Precision: 0.05999268381904646\n",
      "Mean Recall: 0.35446685878962536\n",
      "Mean F Score: 0.10261758264678278\n",
      "Mean Balanced Accuracy: 0.6252740856098484\n"
     ]
    }
   ],
   "source": [
    "tiempo = ['hora_0', 'hora_1',\n",
    "         'hora_2', 'hora_3',\n",
    "         'hora_4', 'hora_5',\n",
    "         'hora_7', 'hora_11',\n",
    "         'hora_13', 'hora_15',\n",
    "         'hora_16', 'hora_17',\n",
    "         'hora_18', 'hora_19',\n",
    "         'hora_20', 'hora_22',\n",
    "         'hora_23',  'dia_sem_4',\n",
    "         'dia_sem_5', 'dia_sem_6',\n",
    "         'festivo', 'Mes_Abril',\n",
    "         'Mes_Agosto', 'Mes_Enero',\n",
    "         'Mes_Febrero', 'Mes_Julio',\n",
    "         'Mes_Mayo', 'Mes_Septiembre',\n",
    "         'Year_2017', 'Year_2018', 'Year_2019']\n",
    "\n",
    "vars_sinTiempo = []\n",
    "for col in vars_voto:\n",
    "    if not col in tiempo:\n",
    "        vars_sinTiempo.append(col)\n",
    "\n",
    "obtencion_metricas(clasificadores,vars_sinTiempo,X_train_under_z,Y_train_under,X_val_z,Y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
