{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección final de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Realizamos el cambio de directoroi de trabajo al \"Directorio Base\" que se\n",
    "current_dir = os.getcwd()\n",
    "base_path = os.path.dirname(current_dir)\n",
    "\n",
    "os.chdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasal\\Anaconda3\\envs\\PI2\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import scripts.funciones as funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.base import clone\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga y preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ini = dt.datetime(2017,6,1)\n",
    "d_fin = dt.datetime(2019,8,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "version = 'verFinal'\n",
    "\n",
    "### params\n",
    "freq1 = '1D'\n",
    "freq2 = '3D'\n",
    "freq3 = '7D'\n",
    "freq4 = '14D'\n",
    "freq5 = '30D'\n",
    "freq6 = '60D'\n",
    "\n",
    "### Realizamos la lectura de la informacion climatica en el rango de fechas\n",
    "### especificado, incluye la etiqueta de si ocurre o no un accidente. \n",
    "### Posteriormente, en la organizacion de la informacion climatica, lo\n",
    "### que se hace es agregar las variables con la informacion distribucional\n",
    "### de las ultimas 5 horas de la info climatica\n",
    "data = funciones.read_clima_accidentes(d_ini, d_fin, poblado = True)\n",
    "data_org = funciones.organizar_data_infoClima(data)\n",
    "\n",
    "\n",
    "### agregamos la informacion relacionada a la cantidad de accidentes ocurridas\n",
    "### en las ultimas X horas\n",
    "### Agregar senales\n",
    "senales = [freq1, freq2, freq3, freq4, freq5, freq6]\n",
    "d_ini_acc = d_ini - dt.timedelta(days = int(freq6.replace('D', '')))  ### freq mayor\n",
    "raw_accidentes = funciones.read_accidentes(d_ini_acc, d_fin)\n",
    "for fresen in senales:\n",
    "    data_org = funciones.obtener_accidentes_acumulados(data_org, \n",
    "                                                        raw_accidentes, \n",
    "                                                        freq = fresen)\n",
    "\n",
    "\n",
    "### Convertimos la bariable de Barrios en variable dummy para ser incluida\n",
    "### en el modelo\n",
    "data_org['poblado'] = data_org['BARRIO']\n",
    "data_org= pd.get_dummies(data_org, columns=['poblado'])\n",
    "\n",
    "### Relizamos la particion del conjunto de datos en las variables\n",
    "### explicativas (X) y la variable respuesta (Y)\n",
    "X = data_org.drop(columns = ['TW','BARRIO','Accidente','summary'])\n",
    "Y = data_org['Accidente'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dividimos el conjunto de datos en entrenamiento y validacion\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, \n",
    "                                                  Y,\n",
    "                                                  stratify = Y,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Realizamos resampling combinando Tomek Links y Random Undersampling\n",
    "\n",
    "### Tomek Link\n",
    "tomeklinks = TomekLinks()\n",
    "X_tom, y_tom = tomeklinks.fit_sample(X_train, Y_train)\n",
    "\n",
    "### Random Undersampling\n",
    "rus = RandomUnderSampler(sampling_strategy = 30/70,random_state = 42)\n",
    "X_train_under, Y_train_under = rus.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Estandarizacion del conjunto de datos\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_under)\n",
    "\n",
    "X_train_under_z = pd.DataFrame(scaler.transform(X_train_under), columns = X_train_under.columns)\n",
    "X_val_z = pd.DataFrame(scaler.transform(X_val), columns = X_val.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de modelos con las variables seleccionadas por los 3 métodos del Notebook Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier1 = XGBClassifier(n_estimators = 300, \n",
    "                           max_depth = 2,\n",
    "                           random_state = 42)\n",
    "\n",
    "Classifier2 = RandomForestClassifier(bootstrap=False,  \n",
    "                             criterion='entropy',\n",
    "                             max_features='auto',\n",
    "                             n_estimators=500, \n",
    "                             max_depth=10,\n",
    "                             random_state=42,\n",
    "                             warm_start=False)\n",
    "\n",
    "Classifier3 = LogisticRegression()\n",
    "\n",
    "clasificadores = [Classifier1, Classifier2, Classifier3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'analisis_var_relevantes.json'\n",
    "path = os.path.join(base_path, f'models/verFinal/{file_name}')\n",
    "with open(path, 'r') as f:\n",
    "    info_vars = json.load(f)\n",
    "\n",
    "vars_backward = info_vars['forward']['features']\n",
    "vars_lasso = info_vars['lasso']['features']\n",
    "vars_AG = info_vars['AG']['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtencion_metricas(clasificadores,variables,X,Y,X_val,Y_val):\n",
    "    \n",
    "    ROC = []\n",
    "    PR = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    fscore = []\n",
    "    bAccuracY = []\n",
    "\n",
    "    for clf in clasificadores:\n",
    "        clf_mod = clone(clf)\n",
    "        clf_mod.fit(X[variables],Y)\n",
    "\n",
    "        ### Metricas en validation\n",
    "\n",
    "        preds_val = clf_mod.predict_proba(X_val[variables])\n",
    "        labels_val = clf_mod.predict(X_val[variables])\n",
    "\n",
    "        ROC_mod = metrics.roc_auc_score(Y_val,preds_val[:,1])\n",
    "        PR_mod = funciones.precision_recall_auc_score(Y_val,preds_val[:,1])\n",
    "        precision_mod = metrics.precision_score(Y_val,labels_val)\n",
    "        recall_mod = metrics.recall_score(Y_val,labels_val)\n",
    "        f1_mod = metrics.f1_score(Y_val,labels_val)\n",
    "        bAccuracY_mod = metrics.balanced_accuracy_score(Y_val,labels_val)\n",
    "\n",
    "        ROC.append(ROC_mod)\n",
    "        PR.append(PR_mod)\n",
    "        precision.append(precision_mod) \n",
    "        recall.append(recall_mod)\n",
    "        fscore.append(f1_mod)\n",
    "        bAccuracY.append(bAccuracY_mod)\n",
    "\n",
    "\n",
    "    print(f'Mean ROC: {np.mean(ROC)}')\n",
    "    print(f'Mean PR: {np.mean(PR)}')\n",
    "    print(f'Mean Precision: {np.mean(precision)}')\n",
    "    print(f'Mean Recall: {np.mean(recall)}')\n",
    "    print(f'Mean F Score: {np.mean(fscore)}')\n",
    "    print(f'Mean Balanced Accuracy: {np.mean(bAccuracY)}')\n",
    "    \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo vars Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC: 0.7757022987898026\n",
      "Mean PR: 0.05939209824665229\n",
      "Mean Precision: 0.06630422448416058\n",
      "Mean Recall: 0.4176272814601345\n",
      "Mean F Score: 0.11424587305043066\n",
      "Mean Balanced Accuracy: 0.6536123142806112\n"
     ]
    }
   ],
   "source": [
    "obtencion_metricas(clasificadores,vars_lasso,X_train_under_z,Y_train_under,X_val_z,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo vars backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC: 0.7784974009479866\n",
      "Mean PR: 0.05853722797815569\n",
      "Mean Precision: 0.07134124808884765\n",
      "Mean Recall: 0.32372718539865514\n",
      "Mean F Score: 0.11234791913566178\n",
      "Mean Balanced Accuracy: 0.6213084789940312\n"
     ]
    }
   ],
   "source": [
    "obtencion_metricas(clasificadores,vars_backward,X_train_under_z,Y_train_under,X_val_z,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo vars Algoritmo Genetico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC: 0.7699717666036646\n",
      "Mean PR: 0.05848248924610744\n",
      "Mean Precision: 0.06581857686046362\n",
      "Mean Recall: 0.4068203650336215\n",
      "Mean F Score: 0.11324722719044937\n",
      "Mean Balanced Accuracy: 0.6493277107914829\n"
     ]
    }
   ],
   "source": [
    "obtencion_metricas(clasificadores,vars_AG,X_train_under_z,Y_train_under,X_val_z,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union de las variables de los 3 metodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC: 0.7754382893212016\n",
      "Mean PR: 0.05929180649204935\n",
      "Mean Precision: 0.06647186043821542\n",
      "Mean Recall: 0.4166666666666667\n",
      "Mean F Score: 0.11442794780618805\n",
      "Mean Balanced Accuracy: 0.6534218306979587\n"
     ]
    }
   ],
   "source": [
    "vars_union = list(set.union(set(vars_AG),set(vars_backward),set(vars_lasso)))\n",
    "obtencion_metricas(clasificadores,vars_union,X_train_under_z,Y_train_under,X_val_z,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interseccion de los 3 metodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC: 0.74808948430526\n",
      "Mean PR: 0.04954900217414624\n",
      "Mean Precision: 0.06816101388965916\n",
      "Mean Recall: 0.21373679154658984\n",
      "Mean F Score: 0.0955604698774314\n",
      "Mean Balanced Accuracy: 0.5764683490420133\n"
     ]
    }
   ],
   "source": [
    "vars_intersec = list(set.intersection(set(vars_AG),set(vars_backward),set(vars_lasso)))\n",
    "obtencion_metricas(clasificadores,vars_intersec,X_train_under_z,Y_train_under,X_val_z,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voto de los  3 metodos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC: 0.7775714076139798\n",
      "Mean PR: 0.0594891099789445\n",
      "Mean Precision: 0.0681817573505847\n",
      "Mean Recall: 0.4121037463976946\n",
      "Mean F Score: 0.11652741769906107\n",
      "Mean Balanced Accuracy: 0.6528119125609653\n"
     ]
    }
   ],
   "source": [
    "all_vars = pd.DataFrame(X_train.columns.values, columns = ['vars'])\n",
    "all_vars['lasso'] = all_vars['vars'].apply(lambda x: 1 if x in vars_lasso else 0)\n",
    "all_vars['backward'] = all_vars['vars'].apply(lambda x: 1 if x in vars_backward else 0)\n",
    "all_vars['AG'] = all_vars['vars'].apply(lambda x: 1 if x in vars_AG else 0)\n",
    "\n",
    "all_vars['Votos'] = all_vars['lasso'] + all_vars['backward'] + all_vars['AG']\n",
    "vars_voto = list(all_vars[all_vars['Votos']>=2]['vars'].values)\n",
    "\n",
    "obtencion_metricas(clasificadores,vars_voto,X_train_under_z,Y_train_under,X_val_z,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resultados = {'lasso':{'num_features':len(vars_lasso),\n",
    "                       'features':list(vars_lasso)},\n",
    "              'forward':{'num_features':len(vars_backward),\n",
    "                       'features':vars_backward},\n",
    "              'AG':{'num_features':len(vars_AG),\n",
    "                    'features':vars_AG},\n",
    "              'union':{'num_features':len(vars_union),\n",
    "                    'features':vars_union},\n",
    "              'interseccion':{'num_features':len(vars_intersec),\n",
    "                    'features':vars_intersec},\n",
    "              'voto':{'num_features':len(vars_voto),\n",
    "                    'features':vars_voto}\n",
    "              }\n",
    "\n",
    "\n",
    "with open(f'{base_path}/models/{version}/vars_relevantes_final.json','w') as json_file:\n",
    "    json.dump(Resultados, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
