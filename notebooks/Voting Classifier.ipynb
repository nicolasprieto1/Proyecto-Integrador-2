{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier con los mejores 3 modelos obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como modelo adicional a los considerados, utilizaremos un modelo ensamblado considerando los 3 mejores modelos obtenidos al momento de entrenamiento. Así, en este notebook utilizaremos el voto de los 3 mejores modelos para obtener la predicción de las fallas y así posteriormente, evaluar el desempeño para entrar en comparación con los demás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasal\\Anaconda3\\envs\\PI2\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Realizamos el cambio de directoroi de trabajo al \"Directorio Base\" que se\n",
    "current_dir = os.getcwd()\n",
    "base_path = os.path.dirname(current_dir)\n",
    "\n",
    "os.chdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.classifier import EnsembleVoteClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.funciones as funciones\n",
    "from scripts.clase_model.modelo import Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organización de la información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos la información incluyendo tanto la ventana de tiempo de entrenamiento como la de prueba. Para esto, organizamos la información acorde a las caracteristicas del modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ini = dt.datetime(2017,6,1)\n",
    "d_fin = dt.datetime(2020,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "version = 'verFinal'    \n",
    "mod_version = funciones.carga_model(base_path, f'models/{version}', version)\n",
    "\n",
    "if 'model' in mod_version:\n",
    "    print(\"Model loaded\")\n",
    "    mod = mod_version['model'].steps[0][1]\n",
    "    model_sel = mod_version['model'].steps[1][1]\n",
    "else:\n",
    "    print(\"No model found\")\n",
    "    \n",
    "\n",
    "data = funciones.read_clima_accidentes(d_ini, d_fin, poblado = True)\n",
    "data_org = funciones.organizar_data_infoClima(data)\n",
    "\n",
    "### agregamos la informacion relacionada a la cantidad de accidentes ocurridas\n",
    "### en las ultimas X horas\n",
    "\n",
    "### En caso que se considere acumulado de fallas, realiza la validacion\n",
    "### si el modelo entrenado tiene la frecuencia utilizada\n",
    "try:\n",
    "    senales = mod.freq1\n",
    "    freq2 = mod.freq2\n",
    "except Exception as e:\n",
    "    print(f'Problemas con las frecuencias de las senales {e}')\n",
    "    freq1 = '1H'\n",
    "    freq2 = '1H'\n",
    "\n",
    "d_ini_acc = d_ini - dt.timedelta(days = int(freq2.replace('D', '')))  ### freq mayor\n",
    "raw_accidentes = funciones.read_accidentes(d_ini_acc, d_fin)\n",
    "for fresen in senales:\n",
    "    data_org = funciones.obtener_accidentes_acumulados(data_org, \n",
    "                                                        raw_accidentes,\n",
    "                                                       freq = fresen)\n",
    "\n",
    "data_org['poblado'] = data_org['BARRIO']\n",
    "data_org= pd.get_dummies(data_org, columns=['poblado'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la división del conjunto de datos en entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ini_train = dt.datetime(2017,6,1)\n",
    "d_fin_train = dt.datetime(2019,8,1)  \n",
    "\n",
    "d_ini_test = dt.datetime(2019,8,1)\n",
    "d_fin_test = dt.datetime(2020,1,1)\n",
    "\n",
    "train = (data_org['TW']>= d_ini_train) & (data_org['TW']< d_fin_train)\n",
    "test = (data_org['TW']>= d_ini_test) & (data_org['TW']< d_fin_test)\n",
    "    \n",
    "X_train = data_org[train].drop(columns = ['TW','BARRIO','Accidente','summary']).reset_index(drop = True)\n",
    "Y_train = data_org[train]['Accidente'].reset_index(drop = True)\n",
    "\n",
    "X_test = data_org[test].drop(columns = ['TW','BARRIO','Accidente','summary']).reset_index(drop = True)\n",
    "Y_test = data_org[test]['Accidente'].reset_index(drop = True)\n",
    "\n",
    "X_train = X_train[mod.cols_order]\n",
    "X_test = X_test[mod.cols_order]\n",
    "\n",
    "X_train2, X_val, Y_train2, Y_val = train_test_split(X_train, \n",
    "                                        Y_train,\n",
    "                                        stratify = Y_train,\n",
    "                                        test_size = 0.2,\n",
    "                                        random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar Modelos Entrenamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos en memoria los 3 mejores modelos obtenidos, y los ensamblamos en un clasificador que los tomará y en base a la predicción de los 3 modelos, entregará una única predicción de ocurrencia del accidente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1 = funciones.carga_model(base_path, f'models/{version}', 'nn_20200513_0827')['model']\n",
    "mod2 = funciones.carga_model(base_path, f'models/{version}', 'logistic_20200513_0827')['model']\n",
    "mod3 = funciones.carga_model(base_path, f'models/{version}', 'xtree_20200513_0827')['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleVoteClassifier(clfs=[Pipeline(memory=None,\n",
       "                                      steps=[('scaler',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('nn',\n",
       "                                              MLPClassifier(activation='identity',\n",
       "                                                            alpha=0.05,\n",
       "                                                            batch_size='auto',\n",
       "                                                            beta_1=0.9,\n",
       "                                                            beta_2=0.999,\n",
       "                                                            early_stopping=False,\n",
       "                                                            epsilon=1e-08,\n",
       "                                                            hidden_layer_sizes=(29,\n",
       "                                                                                53),\n",
       "                                                            learning_rate='constant',\n",
       "                                                            learning_rate_init=0.001,\n",
       "                                                            max_fun=15000,\n",
       "                                                            max_it...\n",
       "                                                                   criterion='entropy',\n",
       "                                                                   max_depth=20,\n",
       "                                                                   max_features='log2',\n",
       "                                                                   max_leaf_nodes=None,\n",
       "                                                                   max_samples=None,\n",
       "                                                                   min_impurity_decrease=0.0,\n",
       "                                                                   min_impurity_split=None,\n",
       "                                                                   min_samples_leaf=1,\n",
       "                                                                   min_samples_split=2,\n",
       "                                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                                   n_estimators=500,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   oob_score=False,\n",
       "                                                                   random_state=42,\n",
       "                                                                   verbose=0,\n",
       "                                                                   warm_start=False))],\n",
       "                                      verbose=False)],\n",
       "                       refit=False, verbose=0, voting='hard',\n",
       "                       weights=[1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VotingClassifier = EnsembleVoteClassifier(clfs=[mod1, mod2, mod3], weights=[1,1,1], refit=False)\n",
    "VotingClassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las métricas del modelo en el conjunto de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_val = pd.read_csv('data/validation.csv')\n",
    "Y_val = X_val['Accidente']\n",
    "\n",
    "X_val = X_val[mod.cols_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = VotingClassifier.predict(X_val)\n",
    "proba = VotingClassifier.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.7844021022705707\n",
      "PR-AUC: 0.060799060893915374\n",
      "bAccuracy: 0.666029051685836\n",
      "fScore: 0.11473463049237234\n",
      "precision: 0.06569724866617847\n",
      "recall: 0.45244956772334294\n"
     ]
    }
   ],
   "source": [
    "ROC = metrics.roc_auc_score(Y_val, proba[:,1])\n",
    "PR = funciones.precision_recall_auc_score(Y_val, proba[:,1])\n",
    "bAccuracy = metrics.balanced_accuracy_score(Y_val,preds) \n",
    "fScore = metrics.f1_score(Y_val,preds) \n",
    "precision = metrics.precision_score(Y_val,preds)\n",
    "recall = metrics.recall_score(Y_val,preds)\n",
    "\n",
    "print(f'ROC-AUC: {ROC}')\n",
    "print(f'PR-AUC: {PR}')\n",
    "print(f'bAccuracy: {bAccuracy}')\n",
    "print(f'fScore: {fScore}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\pasal\\\\Google Drive\\\\EAFIT\\\\Ciencia de Datos y Analitica\\\\02 Segundo Semestre\\\\Proyecto Integrador\\\\Proyecto-Integrador-2/models/verFinal\\\\verFinal_voting.sav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Guardo el modelo de voting\n",
    "mod_pipe = Pipeline([('procesador', mod),\n",
    "                    ('modelo', VotingClassifier)])\n",
    "    \n",
    "path_best_mod = os.path.join(f'{base_path}/models/{version}', f\"{version}_voting.sav\")\n",
    "\n",
    "joblib.dump(mod_pipe, path_best_mod) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del modelo en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las métricas del modelo en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = VotingClassifier.predict(X_test)\n",
    "proba = VotingClassifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = metrics.roc_auc_score(Y_test, proba[:,1])\n",
    "bAccuracy = metrics.balanced_accuracy_score(Y_test,preds) \n",
    "fScore = metrics.f1_score(Y_test,preds) \n",
    "precision = metrics.precision_score(Y_test,preds)\n",
    "recall = metrics.recall_score(Y_test,preds)\n",
    "\n",
    "print(f'ROC-AUC: {ROC}')\n",
    "print(f'bAccuracy: {bAccuracy}')\n",
    "print(f'fScore: {fScore}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lift Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1 = funciones.carga_model(base_path, f'models/{version}', 'nn_20200505_2014')['model']\n",
    "\n",
    "Y_test_pred_ = mod1.predict_proba(X_test)[:]\n",
    "skplt.metrics.plot_cumulative_gain(Y_test, Y_test_pred_)\n",
    "plt.show()\n",
    "skplt.metrics.plot_lift_curve(Y_test, Y_test_pred_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_test\n",
    "X_test['TW'] = data_org[test]['TW'].values\n",
    "X_test['BARRIO'] = data_org[test]['BARRIO'].values\n",
    "X_test['Probabilidad'] = Y_test_pred_[:,1]\n",
    "X_test['Prediccion_Accidente'] = (X_test['Probabilidad']>=0.5).astype(int)\n",
    "\n",
    "filt = X_test['TW']== dt.datetime(2019,12,23,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[filt][['TW','BARRIO','Probabilidad','Prediccion_Accidente']].reset_index(drop = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
