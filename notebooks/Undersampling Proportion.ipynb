{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Realizamos el cambio de directoroi de trabajo al \"Directorio Base\" que se\n",
    "current_dir = os.getcwd()\n",
    "base_path = os.path.dirname(current_dir)\n",
    "\n",
    "os.chdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasal\\Anaconda3\\envs\\PI2\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import scripts.funciones as funciones\n",
    "from scripts.clase_model.modelo import Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparacion de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ini = dt.datetime(2017,6,1)\n",
    "d_fin = dt.datetime(2019,8,1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'Analisis'\n",
    "now_date = dt.datetime.now()\n",
    "\n",
    "cv = 3\n",
    "freq1 = '96H'\n",
    "freq2 = '336H'\n",
    "\n",
    "mod = Modelo(now_date, version, base_path, \"\")\n",
    "\n",
    "data = funciones.read_clima_accidentes(d_ini, d_fin, poblado = True)\n",
    "data_org = funciones.organizar_data_infoClima(data)\n",
    "\n",
    "\n",
    "### agregamos la informacion relacionada a la cantidad de accidentes ocurridas\n",
    "### en las ultimas X horas\n",
    "\n",
    "d_ini_acc = d_ini - dt.timedelta(hours = int(freq2.replace('H', '')))\n",
    "raw_accidentes = funciones.read_accidentes(d_ini_acc, d_fin)\n",
    "\n",
    "### Agrega senal a corto plazo\n",
    "data_org = funciones.obtener_accidentes_acumulados(data_org, \n",
    "                                                    raw_accidentes, \n",
    "                                                    freq = freq1)\n",
    "\n",
    "### Agrega senal a largo plazo\n",
    "data_org = funciones.obtener_accidentes_acumulados(data_org, \n",
    "                                                    raw_accidentes, \n",
    "                                                    freq = freq2)\n",
    "\n",
    "data_org['poblado'] = data_org['BARRIO']\n",
    "data_org= pd.get_dummies(data_org, columns=['poblado'])\n",
    "\n",
    "X = data_org.drop(columns = ['TW','BARRIO','Accidente','summary'])\n",
    "Y = data_org['Accidente']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dividimos el conjunto de datos en entrenamiento y validacion\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, \n",
    "                                                  Y,\n",
    "                                                  stratify = Y,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de la proporcion del Random Undersampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "Procesando proporcion 0.05\n",
      "************************************************************\n",
      "Procesando proporcion 0.1\n",
      "************************************************************\n",
      "Procesando proporcion 0.15\n",
      "************************************************************\n",
      "Procesando proporcion 0.2\n",
      "************************************************************\n",
      "Procesando proporcion 0.25\n",
      "************************************************************\n",
      "Procesando proporcion 0.3\n",
      "************************************************************\n",
      "Procesando proporcion 0.35\n",
      "************************************************************\n",
      "Procesando proporcion 0.4\n",
      "************************************************************\n",
      "Procesando proporcion 0.45\n",
      "************************************************************\n",
      "Procesando proporcion 0.5\n",
      "La mejor proporcion de undersampling es 0.5\n",
      "El mejor ROC-AUC en validation es 0.7457376633973676\n"
     ]
    }
   ],
   "source": [
    "proporciones = np.arange(0.05, 0.55, 0.05)\n",
    "\n",
    "best_roc = 0\n",
    "best_prop = 0\n",
    "best_mod = None\n",
    "roc_val = []\n",
    "for prop in proporciones:\n",
    "    \n",
    "    print('***'*20)\n",
    "    print(f'Procesando proporcion {round(prop,2)}')\n",
    "    \n",
    "    tra_0 = int(len(Y_train) - Y_train.sum())\n",
    "    tra_1 = int(Y_train.sum())\n",
    "    \n",
    "    prop_deseada_under = prop\n",
    "    mul_updown = (tra_0 * prop_deseada_under - tra_1 * (1 - prop_deseada_under)) / (tra_0 * prop_deseada_under)   \n",
    "    fac_1 = int(tra_0 * (1 - mul_updown))\n",
    "    \n",
    "    ratio_u = {0 : fac_1, 1 : tra_1}\n",
    "    rus = RandomUnderSampler(sampling_strategy = ratio_u, random_state=42)\n",
    "    X_train_set, y_train_set = rus.fit_sample(X_train, Y_train)\n",
    "\n",
    "    ### Entrena modelo\n",
    "    \n",
    "    clf = RandomForestClassifier(bootstrap=True,  \n",
    "                                 criterion='entropy',\n",
    "                                 max_features='auto',\n",
    "                                 n_estimators=500, \n",
    "                                 random_state=42,\n",
    "                                 warm_start=True)\n",
    "    \n",
    "    clf.fit(X_train_set,y_train_set)\n",
    "\n",
    "\n",
    "    ### Obtencion de metricas en el conjunto de validacion\n",
    "    \n",
    "    preds = clf.predict_proba(X_val)\n",
    "    ROC = roc_auc_score(Y_val,preds[:,1])\n",
    "    \n",
    "    roc_val.append(ROC)\n",
    "    \n",
    "    if ROC > best_roc:\n",
    "        best_roc = ROC\n",
    "        best_prop = prop\n",
    "        best_mod = clf\n",
    "        \n",
    "print(f'La mejor proporcion de undersampling es {best_prop}')\n",
    "print(f'El mejor ROC-AUC en validation es {best_roc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'best_prop':best_prop,\n",
    "       'best_roc': best_roc,\n",
    "       'props': list(proporciones),\n",
    "       'roc_val':roc_val}\n",
    "\n",
    "with open(f'{base_path}/models/{version}/analisis_prop_res.json','w') as json_file:\n",
    "    json.dump(res, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
